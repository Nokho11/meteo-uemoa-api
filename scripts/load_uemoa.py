import pandas as pd
import psycopg2
from psycopg2.extras import execute_batch
from datetime import datetime, timedelta
import logging

# === Configuration de la base de donnÃ©es ===
DB_CONFIG = {
    'dbname': 'entrepot_uemoa',
    'user': 'postgres',
    'password': '    ',  # ğŸ” Ã€ personnaliser
    'host': 'localhost',
    'port': '5432'
}

# === Fichier d'entrÃ©e ===
INPUT_CSV = "/Users/NOKHO/Desktop/Meteo/historique_meteo_uemoa_80villes_clean.csv"

# === Configuration du logging ===
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def safe_float(value):
    """Convertit une valeur en float ou retourne None si invalide"""
    try:
        return float(value)
    except (TypeError, ValueError):
        return None

def initialiser_dim_date(conn):
    """Initialise la table dim_date pour l'annÃ©e 2025"""
    try:
        logger.info("ğŸ” VÃ©rification de la table dim_date...")
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM dim_date WHERE annee = 2025")
        if cursor.fetchone()[0] > 0:
            logger.info("âœ… La table dim_date est dÃ©jÃ  peuplÃ©e pour 2025")
            return

        logger.info("ğŸ“… GÃ©nÃ©ration des dates de 2025...")
        start_date = datetime(2025, 1, 1)
        end_date = datetime(2025, 12, 31)
        dates = []
        current_date = start_date
        while current_date <= end_date:
            dates.append((
                current_date.date(),
                current_date.day,
                current_date.month,
                current_date.year,
                current_date.strftime('%A')
            ))
            current_date += timedelta(days=1)

        logger.info("ğŸ’¾ Insertion dans dim_date...")
        execute_batch(cursor, """
            INSERT INTO dim_date (date, jour, mois, annee, nom_jour)
            VALUES (%s, %s, %s, %s, %s)
            ON CONFLICT (date) DO NOTHING
        """, dates)
        conn.commit()
        logger.info(f"âœ… Table dim_date initialisÃ©e avec {len(dates)} lignes")

    except Exception as e:
        conn.rollback()
        logger.error(f"âŒ Erreur initialisation dim_date : {e}", exc_info=True)
        raise

def charger_donnees():
    """Charge les donnÃ©es nettoyÃ©es dans le schÃ©ma en Ã©toile"""
    conn = None
    try:
        logger.info("ğŸ”— Connexion Ã  PostgreSQL...")
        conn = psycopg2.connect(**DB_CONFIG)

        # Initialiser dim_date
        initialiser_dim_date(conn)

        # Charger le CSV nettoyÃ©
        logger.info(f"ğŸ“‚ Chargement du fichier {INPUT_CSV}...")
        df = pd.read_csv(INPUT_CSV)
        df['datetime'] = pd.to_datetime(df['datetime'])
        logger.info(f"âœ… {len(df)} lignes chargÃ©es depuis le fichier")

        # Remplissage de dim_lieu avec gestion des doublons
        logger.info("ğŸŒ Chargement des lieux dans dim_lieu...")
        with conn.cursor() as cursor:
            # VÃ©rification des lieux existants
            cursor.execute("SELECT ville, pays FROM dim_lieu")
            lieux_existants = set((ville, pays) for (ville, pays) in cursor.fetchall())
            
            lieux_uniques = df[['Ville', 'Pays', 'latitude', 'longitude']].drop_duplicates()
            nouveaux_lieux = []
            
            for _, row in lieux_uniques.iterrows():
                ville = str(row['Ville'])
                pays = str(row['Pays'])
                
                if (ville, pays) not in lieux_existants:
                    nouveaux_lieux.append((
                        ville,
                        pays,
                        safe_float(row['latitude']),
                        safe_float(row['longitude'])
                    ))
            
            if nouveaux_lieux:
                execute_batch(cursor, """
                    INSERT INTO dim_lieu (ville, pays, latitude, longitude)
                    VALUES (%s, %s, %s, %s)
                    ON CONFLICT (ville, pays) DO UPDATE SET
                        latitude = EXCLUDED.latitude,
                        longitude = EXCLUDED.longitude
                """, nouveaux_lieux)
                logger.info(f"âœ… {len(nouveaux_lieux)} nouveaux lieux insÃ©rÃ©s/mis Ã  jour")
            else:
                logger.info("âœ… Aucun nouveau lieu Ã  insÃ©rer")
            conn.commit()

        # Remplissage de dim_conditions avec gestion des doublons
        logger.info("â›… Chargement des conditions mÃ©tÃ©o dans dim_conditions...")
        with conn.cursor() as cursor:
            # VÃ©rification des conditions existantes
            cursor.execute("SELECT conditions FROM dim_conditions")
            conditions_existantes = set(condition for (condition,) in cursor.fetchall())
            
            conditions_uniques = df['conditions'].dropna().unique()
            nouvelles_conditions = []
            
            for condition in conditions_uniques:
                condition_str = str(condition)
                if condition_str not in conditions_existantes:
                    nouvelles_conditions.append((condition_str,))
            
            if nouvelles_conditions:
                execute_batch(cursor, """
                    INSERT INTO dim_conditions (conditions)
                    VALUES (%s)
                    ON CONFLICT (conditions) DO NOTHING
                """, nouvelles_conditions)
                logger.info(f"âœ… {len(nouvelles_conditions)} nouvelles conditions insÃ©rÃ©es")
            else:
                logger.info("âœ… Aucune nouvelle condition Ã  insÃ©rer")
            conn.commit()

        # Remplissage de faits_meteo avec upsert
        logger.info("ğŸ“ˆ Insertion des donnÃ©es dans faits_meteo...")
        with conn.cursor() as cursor:
            # RÃ©cupÃ©rer les mappings
            cursor.execute("SELECT id_dim_lieu, ville, pays FROM dim_lieu")
            lieux_map = {(ville, pays): id_lieu for (id_lieu, ville, pays) in cursor.fetchall()}

            cursor.execute("SELECT id_dim_condition, conditions FROM dim_conditions")
            conditions_map = {condition: id_cond for (id_cond, condition) in cursor.fetchall()}

            # PrÃ©parer les donnÃ©es
            data_faits = []
            for _, row in df.iterrows():
                id_lieu = lieux_map.get((str(row['Ville']), str(row['Pays'])))
                id_condition = conditions_map.get(str(row['conditions'])) if pd.notna(row['conditions']) else None

                if id_lieu and id_condition:
                    data_faits.append((
                        row['datetime'].date(),
                        id_lieu,
                        id_condition,
                        safe_float(row.get('temp')),
                        safe_float(row.get('tempmax')),
                        safe_float(row.get('tempmin')),
                        safe_float(row.get('feelslike')),
                        safe_float(row.get('feelslikemax')),
                        safe_float(row.get('feelslikemin')),
                        safe_float(row.get('dew')),
                        safe_float(row.get('precip')),
                        safe_float(row.get('precipcover')),
                        safe_float(row.get('windgust')),
                        safe_float(row.get('windspeed')),
                        safe_float(row.get('winddir')),
                        safe_float(row.get('cloudcover')),
                        safe_float(row.get('solarradiation')),
                        safe_float(row.get('solarenergy')),
                        safe_float(row.get('uvindex'))
                    ))

            if data_faits:
                execute_batch(cursor, """
                    INSERT INTO faits_meteo (
                        datecollect, id_dim_lieu, id_dim_condition, temp, tempmax, tempmin,
                        feelslike, feelslikemax, feelslikemin, dew, precip,
                        precipcover, windgust, windspeed, winddir, cloudcover,
                        solarradiation, solarenergy, uvindex
                    ) VALUES (
                        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                        %s, %s, %s, %s, %s, %s, %s, %s
                    )
                    ON CONFLICT (datecollect, id_dim_lieu) DO UPDATE SET
                        id_dim_condition = EXCLUDED.id_dim_condition,
                        temp = EXCLUDED.temp,
                        tempmax = EXCLUDED.tempmax,
                        tempmin = EXCLUDED.tempmin,
                        feelslike = EXCLUDED.feelslike,
                        feelslikemax = EXCLUDED.feelslikemax,
                        feelslikemin = EXCLUDED.feelslikemin,
                        dew = EXCLUDED.dew,
                        precip = EXCLUDED.precip,
                        precipcover = EXCLUDED.precipcover,
                        windgust = EXCLUDED.windgust,
                        windspeed = EXCLUDED.windspeed,
                        winddir = EXCLUDED.winddir,
                        cloudcover = EXCLUDED.cloudcover,
                        solarradiation = EXCLUDED.solarradiation,
                        solarenergy = EXCLUDED.solarenergy,
                        uvindex = EXCLUDED.uvindex
                """, data_faits, page_size=1000)
                logger.info(f"âœ… {len(data_faits)} observations insÃ©rÃ©es/mises Ã  jour dans faits_meteo")
            else:
                logger.info("âœ… Aucune nouvelle observation Ã  insÃ©rer")
            conn.commit()

        logger.info("ğŸ‰ Chargement des donnÃ©es terminÃ© avec succÃ¨s.")

    except Exception as e:
        if conn:
            conn.rollback()
        logger.error(f"âŒ Erreur lors du chargement : {e}", exc_info=True)
        raise
    finally:
        if conn:
            conn.close()

if __name__ == "__main__":
    charger_donnees()
